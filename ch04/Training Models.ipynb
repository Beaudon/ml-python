{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models\n",
    "This notebook is dedicated to chapter 4 of the book.\n",
    "\n",
    "Exploring how models can be trained\n",
    "\n",
    "## Linear Regression Model\n",
    "### Definition\n",
    "We can define the linear model as follows:\n",
    "$$\n",
    "\\hat{y}=\\theta_{0} + \\theta_{1}x_{1}+\\theta_{2}x_{2}+\\dots+\\theta_{n}x_{n}\n",
    "$$\n",
    "Where:\n",
    "* $\\hat{y}$ is the predicted value\n",
    "* $n$ is the number of features\n",
    "* $x_{i}$ is the $x^{ith}$ feature value (i.e., the instance attribute values)\n",
    "* $\\theta_{j}$ is the $j^{th}$ model parameter including the bias term $\\theta_0$ and the feature weights $\\theta_1,\\theta_2,\\dots,\\theta_n$\n",
    "\n",
    "And in vectorized form:\n",
    "$$\n",
    "\\hat{y}=h_{\\theta}(X)=\\theta^T X\n",
    "$$\n",
    "Where:\n",
    "* $\\hat{y}$ is again the predicted value\n",
    "* $\\theta$ is the model's *parameter vector*, containing the bias term $\\theta_0$, and the feature weights $\\theta_1$ to $\\theta_n$\n",
    "* $\\theta^T$ is the transpose of $\\theta$, a row vector instead of a column vector.\n",
    "* $X$ is the instance's *feature vector*, containing $x_0$ to $x_n$ **with $x_0$ always equal to $1$.**\n",
    "* $\\theta^TX$ is the dot product of $\\theta^T$ and $X$\n",
    "* $h_{\\theta}$ is the hypothesis function, using the model parameters $\\theta$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
