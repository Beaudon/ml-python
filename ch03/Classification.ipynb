{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3, Classification\n",
    "We will work with MNIST dataset for classifying handwritten digits with the corresponding actual value. Scikit provides handy functions to get this dataset.\n",
    "\n",
    "#### Warning!\n",
    "The book uses a different method to download MNIST dataset but it seems it is not working, hence I'm using the official sickit's method to download mnist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def print_samples(X, y, shape = (2, 2), raw=False):\n",
    "    \"\"\"Print n random samples\"\"\"\n",
    "    if raw:\n",
    "        rand_indx = np.random.randint(0, len(X), shape[0])\n",
    "        samples = zip(X[rand_indx], y[rand_indx])\n",
    "        print(list(samples))\n",
    "    else:\n",
    "        n_samples = int(shape[0]) * int(shape[1])\n",
    "        rand_indx = np.random.randint(0, len(X), n_samples)\n",
    "        samples = zip(X[rand_indx], y[rand_indx])\n",
    "        idx = 1\n",
    "        for features, label in samples:\n",
    "            # X is a flattened array, to print the image we need\n",
    "            # to reshape it into a 28 x 28 figure\n",
    "            plt.subplot(*shape, idx)\n",
    "            plt.tight_layout()\n",
    "            plt.imshow(features.reshape(28,28), cmap=plt.cm.gray_r)\n",
    "            plt.title(\"Label: {}\".format(label))\n",
    "            idx+=1\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_samples(X, y, (2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remember!\n",
    "Always create the training, validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning\n",
    "You have to keep in mind the data you are dealing with and the possible algorithms and validation methods you are going to use. Some algorithms are sensitive to the order of the training set hence we don't want to feed them in the same order every time.\n",
    "\n",
    "Also, if we are going to use k-fold cross-validation, we want to ensure that every fold get's samples of every number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a binary classifier\n",
    "Say we want to just be able to detect if a particular sample is a 5 or not, this is an example of a binary classifier i.e., true or false.\n",
    "\n",
    "### Warning\n",
    "The way we loaded MNIST, the labels are strings not ints, hence we test with the string '5' as opposed to the int 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This simply will change the labels to True, the number is a 5, and False, is not\n",
    "y_train_5 = (y_train == '5')\n",
    "y_test_5 = (y_test == '5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "This algorithm handles large datasets efficiently and works on training instances independently, i.e., one at a time.\n",
    "\n",
    "We'll use sickit's ```SGDClassifier```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ferro/anaconda3/envs/Deeplearning/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This means the first digit was predicted to be a five\n",
    "sgd_clf.predict(X_train[10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's measure the model's performance with K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ferro/anaconda3/envs/Deeplearning/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/ferro/anaconda3/envs/Deeplearning/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/ferro/anaconda3/envs/Deeplearning/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.96915, 0.9617 , 0.9631 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "90-95% of accuracy!, very impressive, before continuing, let's see what happens when we create a model exclusively for not-5 class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91005, 0.90915, 0.90975])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "    \n",
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow!, almost the same score, it seems our model is not that good after all. This is because of all the samples, only 10% of them are actually 5. So a model that predicts 90% of the time the image is not a 5 given this circumstances, it is not that useful.\n",
    "\n",
    "This is a hint to say that 'accuracy' is not always the best metric for classifiers, especialluy when dealing with skewed datasets.\n",
    "\n",
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ferro/anaconda3/envs/Deeplearning/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/ferro/anaconda3/envs/Deeplearning/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/ferro/anaconda3/envs/Deeplearning/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53988,   591],\n",
       "       [ 1530,  3891]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of the confusion matrix represents the actual classes while each column represents the predicted values, where they cross is the correct classified categories, for instance, the first row represents non-5 and the first column represents predicted non-5, so, we could interpret as: Of all real non-5's we correctly predicted 53988.\n",
    "\n",
    "The second column represents actual 5's, so we could read: Of all real non-5's we wrongly classified 591 as 5's.\n",
    "\n",
    "## Concise metrics\n",
    "The matrix alone is useful but we might need to calculate more concise metrics to have a better representation or \"score\" for the data. for instance:\n",
    "\n",
    "### Precision\n",
    "\"Of all true positives and false positives, how much my model was able to hit\", this metric tries to evaluate the predictions against the reality, think of it as a \"row\" metric.\n",
    "$$\n",
    "precision=\\frac{TP}{TP + FP}\n",
    "$$\n",
    "### Recall\n",
    "\"Of all true positives and false negatives, how much mu model was able to hit\", this metrics tries to evaluate how sensitive the predictions are, say, how much varies the predictions for a specific class, think of it as a \"column\" metric\n",
    "$$\n",
    "recall = \\frac{TP}{TP + FN}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8681392235609103\n",
      "Recall:  0.7177642501383509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "ps = precision_score(y_train_5, y_train_pred)\n",
    "rs = recall_score(y_train_5, y_train_pred)\n",
    "\n",
    "print(\"Precision: \", ps)\n",
    "print(\"Recall: \", rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model does not look as good as before, this means it was only to correctly predict 86% of the 5s, and it was only able to detect 71% of the 5s.\n",
    "\n",
    "### F1 score - harmonic mean of precision and recall\n",
    "It is often convinient to combien both precision and recall into a single metric called $F_1 score$. Whereas the regular mean treats all values equally, the harmonic mean gives much more weight to low values.\n",
    "\n",
    "$$\n",
    "F_1 =\\frac{2}{\\frac{1}{precision}+\\frac{1}{recall}} = 2\\times \\frac{precision\\times recall}{precision + recall} = \\frac{TP}{TP + \\frac{FN + FP}{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7858224780369585"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
